{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2Bj-ACkP4J9"
   },
   "source": [
    "# Actividad 3. Algoritmo _Apriori_\n",
    "<hr/>\n",
    "\n",
    "**Profesor:** \n",
    "- Mauricio Arriagada\n",
    "\n",
    "**Ayudantes:**\n",
    "- Felipe Barrientos (fnbarrientos@uc.cl)\n",
    "- Javier Dreves (jidreves@uc.cl)\n",
    "- Joaquin Eichholz (jeichholz3@uc.cl)\n",
    "- Astrid San Martín (aesanmar@uc.cl)\n",
    "\n",
    "\n",
    "**Antes de comenzar:**\n",
    "\n",
    "- Laboratorio debe ser realizado **de forma individual**. Obviamente, se pueden discutir ideas, pero cualquier intercambio de códigos **no está permitido**.\n",
    "- Recuerda orientar tu programación a un paradigma funcional.\n",
    "- **¡ Comenta todo tu código !**\n",
    "\n",
    "**Instrucciones de entrega:**\n",
    "\n",
    "- Debe entregar este laboratorio por `siding`, en sección `cuestionarios`. Descargar archivo \".ipynb\" a su equipo y luego subirlo. (También pueden trabajarlo en colab)\n",
    "- Plazo máximo de entrega: **Martes 3 de Agosto, 10.59 pm.**\n",
    "\n",
    "**Evaluación:**\n",
    "- La estructura del código = 0.5\n",
    "- Salida exitosa = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Z4_UtDCP4J_"
   },
   "source": [
    "<hr/>\n",
    "\n",
    "**Contexto**\n",
    "\n",
    "Este laboratorio consiste en estudiar en profundidad e implementar el algoritmo `Apriori`, el cual tiene por\n",
    "objetivo encontrar `itemsets` frecuentes dentro de una base de datos y generar las reglas de asociación que\n",
    "superan umbrales de soporte y confianza.\n",
    "En `data mining`, las reglas de asociación son ampliamente utilizadas para descubrir relaciones entre\n",
    "variables en bases de datos de gran tamaño [Agrawal et al., 1993]. Aplicaciones clásicas de este tipo de\n",
    "estrategias pueden ser encontradas en análisis de compras y de características socio-demográficas desde\n",
    "bases de datos censales.\n",
    "\n",
    "**Base de Datos**\n",
    "\n",
    "La base de datos a utilizar corresponde a una parte de la información liberada por `Spotify` para el _RecSys_ Challenge 2018 1 y contiene información de listas de reproducción creadas por usuarios de `Spotify`. Cada lista contiene un número variable de canciones \n",
    "\n",
    "**Objetivo**\n",
    "\n",
    "Para este laboratorio, aplicaremos el algoritmo `a priori` en una base de datos de listas de reproducción publicada por `Spotify`. El objetivo es obtener itemsets de canciones frecuentes y crear reglas de asociación con estos sets. \n",
    "\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## Instrucciones \n",
    "\n",
    "1. **Implementar el algoritmo Apriori**: Se espera que el algoritmo sea capaz de retornar a lo menos 3 reglas de asociación entre canciones. El alumno debe ir probando con distintos humbrales  para el la ejecución del código tome un tiempo razonable pero se puedan tener reglas no triviales. \n",
    "    - Cargar base de datos\n",
    "    - Primera pasada: Eliminar todas las listas que contienen canciones que no pasan el umbral\n",
    "    - Iteraciones posteriores: Generar itemsets con canciones restantes y ver su presencia en las listas que van quedando \n",
    "\n",
    "\n",
    "2. **Presentación de reglas**: Mostrar las reglas encontradas y explicar por qué se eligiron. Se deben incluir conceptos de _support_ y _confidence_ de cada regla. \n",
    "\n",
    "## Recordar \n",
    "\n",
    "- Support = |Itemset| / |T|\n",
    "    - S = |(pañales, leche, cerveza)|\n",
    "\n",
    "- Confidence = |Itemset| / |Itemset - regla|\n",
    "    - C = |(pañales, leche, cerveza)| / |(leche, pañales)|\n",
    "\n",
    "\n",
    "- **Es de suma importancia que el alumno elabore todo el algoritmo desde cero. No está permitido reutilizar código o usar librerías para la implementación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nXVMY_3rP4KA"
   },
   "outputs": [],
   "source": [
    "def load_database(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Esta función debe cargar la base de datos de acuerdo a un path. Esta función puede servir también \n",
    "    como filtro del número de listas de reproducción a usar para probar a priori.\n",
    "    \"\"\"\n",
    "    data = np.load(path)\n",
    "    database = np.array([x for x in data.item().values()])\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordenar(data):\n",
    "    \"\"\"\n",
    "    Esta función define el orden que será utilizado cuando se hagan los joins \n",
    "    \"\"\"\n",
    "    canciones = {}\n",
    "    contador = 0\n",
    "    for lista in data:\n",
    "        for cancion in lista:\n",
    "            if cancion not in canciones:\n",
    "                canciones[cancion]= contador\n",
    "                contador += 1\n",
    "    return canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_soporte(data, itemset=None):\n",
    "    \"\"\"\n",
    "    Esta función saca el soporte de los itemsets\n",
    "    \"\"\"\n",
    "    t = []\n",
    "    canciones = defaultdict(int)\n",
    "    \n",
    "    if itemset == None: \n",
    "        # si es la primera iteración, cuenta las diferentes canciones y sus apariciones\n",
    "        for lista in data:\n",
    "            for cancion in lista:\n",
    "                t.append(cancion)\n",
    "                canciones[tuple(t)] += (1/len(data))\n",
    "                t = []\n",
    "    else:\n",
    "        # si es una iteración diferente cuenta que este el set completo.\n",
    "        for lista in data:\n",
    "            for item in itemset:\n",
    "                if all(x in lista for x in item): # si todos los items estan en la lista\n",
    "                    canciones[item] += (1/len(data))\n",
    "                    \n",
    "    return canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_join(items, orden):\n",
    "    \"\"\"\n",
    "    Esta función genera los joins entre los sets deacuerdo al orden dado.\n",
    "    \"\"\"\n",
    "    itemset= []\n",
    "    \n",
    "    for item in items.keys():\n",
    "        for seg in items.keys():\n",
    "            if item != seg:\n",
    "                \n",
    "                if len(item)==1: #si solo necesitamos formar pares\n",
    "                    \"\"\" revisamos cual de los 2 es mayor e insertamos en orden\"\"\"\n",
    "                    if orden[item[0]]< orden[seg[0]]:  \n",
    "                        tupla = (item[0],seg[0])\n",
    "                    else:\n",
    "                        tupla = (seg[0], item[0])\n",
    "                    itemset.append(tupla)\n",
    "                    \n",
    "                else: # si vamos a generar tuplas de más de largo 2.\n",
    "                    cont = 0\n",
    "               \n",
    "                    for el1, el2 in zip(item, seg):\n",
    "                        cont +=1\n",
    "                        if (el1 != el2 and cont == len(item) ):\n",
    "                            \"\"\"\n",
    "                            si hay un elemento diferente, es el ultimo elemento hacemos join considerando \n",
    "                            el orden inicial dado\n",
    "                            \"\"\"\n",
    "                            \n",
    "                            if ((orden[item[cont-1]] < orden[seg[cont-1]])): \n",
    "                                tupla = item + tuple([seg[cont-1]])\n",
    "                            else:\n",
    "                                tupla = seg + tuple([item[cont-1]])\n",
    "                            itemset.append(tupla)\n",
    "                                \n",
    "                        elif (el1 != el2 and cont != len(item) ):\n",
    "                            break\n",
    "                        else:\n",
    "                            pass\n",
    "                                \n",
    "    return itemset\n",
    "                        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3XixZEfP4KE"
   },
   "outputs": [],
   "source": [
    "def apriori(data, support):\n",
    "    \n",
    "    \"\"\"\n",
    "    Función que debe retornar todos los itemsets que cumplen con el support. Puede ser en una estructura de \n",
    "    diccionario que entregue el itemset y su soporte.\n",
    "    \"\"\"\n",
    "    itemsets = {}\n",
    "    #primero calculo el soporte para los items por si solos \n",
    "    soporte = calcular_soporte(data)\n",
    "    \"\"\"Ya que no se puede deducir nada de un item por sí solo no lo agregué a la lista de items, está comentado \n",
    "    aquí abajo. \"\"\"\n",
    "    # itemsets.update({key: soporte[key] for key in soporte.keys() if soporte[key]>= support})\n",
    "    items = generar_join({key: soporte[key] for key in soporte.keys() if soporte[key]>= support}, orden)\n",
    "    \n",
    "    #Luego realizo un while, mientras se puedan generar mas posibles itemsets \n",
    "    while(items!= []):\n",
    "        soporte= calcular_soporte(data, items)\n",
    "        itemsets.update({key: soporte[key] for key in soporte.keys() if soporte[key]>= support})\n",
    "        items = generar_join({key: soporte[key] for key in soporte.keys() if soporte[key]>= support}, orden)\n",
    "    \n",
    "\n",
    "    \n",
    "    return itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confianza(data, antecedente, consecuente):\n",
    "    \"\"\"Función que calcula la confianza de acuerdo a las diapositivas.\"\"\"\n",
    "    arriba = tuple(antecedente) + tuple(consecuente)\n",
    "    freq_up = 0 \n",
    "    freq_down = 0\n",
    "    for lista in data:\n",
    "        if all(x in lista for x in arriba):\n",
    "            freq_up += 1\n",
    "        if all(j in lista for j in tuple(antecedente)):\n",
    "            freq_down += 1\n",
    "    if freq_down == 0:\n",
    "        return 0\n",
    "    return (freq_up/freq_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_subsets(item):\n",
    "    subs = [[]]\n",
    "    \"\"\"Función que obtiene todos los subsets de un item\"\"\"\n",
    "    for elemento in item:\n",
    "        for sub_set in subs:\n",
    "            subs = subs + [list(sub_set)+ [elemento]]\n",
    "    return [set(i) for i in subs if len(set(i))!=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdWFEKQEP4KH"
   },
   "outputs": [],
   "source": [
    "def rules(itemsets, confidence, data):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retorna las reglas que complen con la confianza pedida.\n",
    "    \"\"\"\n",
    "    rules= [] # rules es un diccionario que como key tiene el antecedente \n",
    "            # y value el consecuente.\n",
    "    for item in itemsets.keys():\n",
    "        set1 = set(item)\n",
    "        subsets = obtener_subsets(item)\n",
    "        for subset in subsets:\n",
    "             if len(set1-subset) != 0:\n",
    "                    conf = confianza(data, set1-subset, subset)\n",
    "                    if conf >= confidence:\n",
    "                        rules.append({'antecedente': tuple(set1-subset), 'consecuente': tuple(subset),'confianza': conf, 'soporte': itemsets[item] })\n",
    "    return rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_database(\"spotify.npy\")\n",
    "datita = data[0:5000]\n",
    "orden = ordenar(datita) # defino un orden para mi dataset\n",
    "\n",
    "itemsets = apriori(datita, 0.025) \n",
    "#defini este soporte minimo ya que con los 10000 datos era uno de los que \n",
    "#arrojaba datos suficientes para ver el algoritmo funcionar, no sé que valor habría sido más conveniente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Despacito - Remix', \"I'm the One\"): 0.027199999999999946,\n",
       " ('Bounce Back', 'goosebumps'): 0.02679999999999995,\n",
       " ('Bounce Back', 'Congratulations'): 0.029199999999999934,\n",
       " ('Bounce Back', 'XO TOUR Llif3'): 0.02519999999999996,\n",
       " ('goosebumps', 'Congratulations'): 0.03319999999999991,\n",
       " ('goosebumps', 'XO TOUR Llif3'): 0.031199999999999922,\n",
       " ('Congratulations', 'XO TOUR Llif3'): 0.037599999999999884,\n",
       " ('XO TOUR Llif3', 'Bank Account'): 0.02999999999999993,\n",
       " ('Caroline', 'Fake Love'): 0.02839999999999994,\n",
       " ('Bounce Back', 'Caroline'): 0.02839999999999994,\n",
       " ('Bounce Back', 'Fake Love'): 0.02639999999999995,\n",
       " ('Congratulations', 'Caroline'): 0.025599999999999956,\n",
       " ('Congratulations', 'Fake Love'): 0.025599999999999956,\n",
       " ('Closer', 'Gold'): 0.025999999999999954,\n",
       " ('goosebumps', 'HUMBLE.'): 0.031199999999999922,\n",
       " ('Congratulations', 'HUMBLE.'): 0.043999999999999845,\n",
       " ('Congratulations', 'Tunnel Vision'): 0.027599999999999944,\n",
       " ('Passionfruit', 'HUMBLE.'): 0.029199999999999934,\n",
       " ('HUMBLE.', 'Tunnel Vision'): 0.028799999999999937,\n",
       " ('Panda', 'Broccoli (feat. Lil Yachty)'): 0.027599999999999944,\n",
       " ('Black Beatles', 'Broccoli (feat. Lil Yachty)'): 0.02519999999999996,\n",
       " ('Bounce Back', 'HUMBLE.'): 0.03319999999999991,\n",
       " ('Bounce Back', 'Bad and Boujee (feat. Lil Uzi Vert)'): 0.031199999999999922,\n",
       " ('Bounce Back', 'Mask Off'): 0.02839999999999994,\n",
       " ('goosebumps', 'Mask Off'): 0.027599999999999944,\n",
       " ('Congratulations',\n",
       "  'Bad and Boujee (feat. Lil Uzi Vert)'): 0.029599999999999932,\n",
       " ('Congratulations', 'Mask Off'): 0.03279999999999991,\n",
       " ('XO TOUR Llif3', 'HUMBLE.'): 0.03959999999999987,\n",
       " ('XO TOUR Llif3', 'Mask Off'): 0.031199999999999922,\n",
       " ('HUMBLE.', 'Broccoli (feat. Lil Yachty)'): 0.027599999999999944,\n",
       " ('HUMBLE.', 'Bad and Boujee (feat. Lil Uzi Vert)'): 0.03359999999999991,\n",
       " ('HUMBLE.', 'Mask Off'): 0.040799999999999864,\n",
       " ('Broccoli (feat. Lil Yachty)',\n",
       "  'No Problem (feat. Lil Wayne & 2 Chainz)'): 0.02799999999999994,\n",
       " ('Broccoli (feat. Lil Yachty)',\n",
       "  'Bad and Boujee (feat. Lil Uzi Vert)'): 0.030399999999999927,\n",
       " ('Bad and Boujee (feat. Lil Uzi Vert)', 'Mask Off'): 0.02799999999999994,\n",
       " ('Caroline', 'HUMBLE.'): 0.030399999999999927,\n",
       " ('Caroline', 'Broccoli (feat. Lil Yachty)'): 0.033999999999999905,\n",
       " ('XO TOUR Llif3', 'Tunnel Vision'): 0.028799999999999937,\n",
       " ('Bank Account', 'HUMBLE.'): 0.027199999999999946,\n",
       " ('Tunnel Vision', 'Mask Off'): 0.027199999999999946,\n",
       " ('Fake Love', 'Bad and Boujee (feat. Lil Uzi Vert)'): 0.027199999999999946,\n",
       " ('Bounce Back', 'iSpy (feat. Lil Yachty)'): 0.029199999999999934,\n",
       " ('Congratulations', 'iSpy (feat. Lil Yachty)'): 0.035599999999999896,\n",
       " ('XO TOUR Llif3', 'iSpy (feat. Lil Yachty)'): 0.02679999999999995,\n",
       " ('Tunnel Vision', 'iSpy (feat. Lil Yachty)'): 0.02519999999999996,\n",
       " ('Caroline', 'Bad and Boujee (feat. Lil Uzi Vert)'): 0.027599999999999944,\n",
       " ('Caroline', 'No Problem (feat. Lil Wayne & 2 Chainz)'): 0.02799999999999994,\n",
       " ('Caroline', 'iSpy (feat. Lil Yachty)'): 0.030799999999999925,\n",
       " ('Mask Off', 'iSpy (feat. Lil Yachty)'): 0.03639999999999989,\n",
       " ('HUMBLE.', 'iSpy (feat. Lil Yachty)'): 0.03599999999999989,\n",
       " ('Closer', 'One Dance'): 0.02679999999999995,\n",
       " ('Closer', 'Roses'): 0.028799999999999937,\n",
       " ('One Dance', 'Panda'): 0.028799999999999937,\n",
       " ('Closer', 'Let Me Love You'): 0.03159999999999992,\n",
       " ('Fake Love', 'iSpy (feat. Lil Yachty)'): 0.02639999999999995,\n",
       " (\"I'm the One\", 'HUMBLE.'): 0.025999999999999954,\n",
       " ('Closer', \"Don't Let Me Down\"): 0.030399999999999927,\n",
       " ('Bad and Boujee (feat. Lil Uzi Vert)',\n",
       "  'iSpy (feat. Lil Yachty)'): 0.030799999999999925,\n",
       " ('Closer', 'Cold Water (feat. Justin Bieber & MØ)'): 0.0347999999999999,\n",
       " ('One Dance', 'Broccoli (feat. Lil Yachty)'): 0.02519999999999996,\n",
       " ('Congratulations',\n",
       "  'HUMBLE.',\n",
       "  'iSpy (feat. Lil Yachty)'): 0.025599999999999956,\n",
       " ('HUMBLE.', 'Mask Off', 'iSpy (feat. Lil Yachty)'): 0.02519999999999996}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reglas finales\n",
    "Estas reglas que se presentan a continuación fueron tomadas de cada itemset que no era de un solo elemento y que pasó el humbral de dado,\n",
    "finalmente, luego de tener cada itemset, se generaron todas las posibles reglas y nos quedamos con las que sobrepasan o son iguales auna confianza del 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'antecedente': ('XO TOUR Llif3',),\n",
       "  'consecuente': ('HUMBLE.',),\n",
       "  'confianza': 0.631578947368421,\n",
       "  'soporte': 0.03959999999999987},\n",
       " {'antecedente': ('Mask Off',),\n",
       "  'consecuente': ('HUMBLE.',),\n",
       "  'confianza': 0.6455696202531646,\n",
       "  'soporte': 0.040799999999999864},\n",
       " {'antecedente': ('Cold Water (feat. Justin Bieber & MØ)',),\n",
       "  'consecuente': ('Closer',),\n",
       "  'confianza': 0.6196581196581197,\n",
       "  'soporte': 0.0347999999999999},\n",
       " {'antecedente': ('HUMBLE.', 'iSpy (feat. Lil Yachty)'),\n",
       "  'consecuente': ('Congratulations',),\n",
       "  'confianza': 0.7032258064516129,\n",
       "  'soporte': 0.025599999999999956},\n",
       " {'antecedente': ('Congratulations', 'iSpy (feat. Lil Yachty)'),\n",
       "  'consecuente': ('HUMBLE.',),\n",
       "  'confianza': 0.6728395061728395,\n",
       "  'soporte': 0.025599999999999956},\n",
       " {'antecedente': ('Mask Off', 'iSpy (feat. Lil Yachty)'),\n",
       "  'consecuente': ('HUMBLE.',),\n",
       "  'confianza': 0.6870748299319728,\n",
       "  'soporte': 0.02519999999999996},\n",
       " {'antecedente': ('HUMBLE.', 'iSpy (feat. Lil Yachty)'),\n",
       "  'consecuente': ('Mask Off',),\n",
       "  'confianza': 0.6516129032258065,\n",
       "  'soporte': 0.02519999999999996}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reglas = rules(itemsets, 0.6, data)\n",
    "reglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "efIug9gDP4KJ"
   },
   "source": [
    "<hr/>\n",
    "<center> <h1>Fin del laboratorio.</h1> </center>\n",
    "​"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Actividad_Apriori.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
